{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7b8e03-c51d-4e48-b3f9-f8c04247d4d8",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Используем датасет с https://www.kaggle.com/mlg-ulb/creditcardfraud#creditcard.csv\n",
    "Файл creditcard.csv поместим в рабочую директорию данного notebook.\n",
    "\n",
    "Признак Time можно рассмотреть, как уникальный идентификатор. Анализ временных рядов мы еще не проходили. Эта колонка, наверное, полезна для определения аномалий (может быть, мошеннические операции предваряют какие-то подготовительные особые транзанкции и отслеживать корреляции каких-то транзанкций во времени было бы полезно), но что с ней делать пока непонятно. Поэтому не будем использовать данную переменную, чтобы не вносила побочных эффектов в поведение алгоритмов.\n",
    "\n",
    "Кроме факторов PCA в dataset есть колонка Amount — объем транзанкции.\n",
    "\n",
    "Данные размеченные: колонка Class содержит метку. Поэтому мы можем использовать алгоритмы с обучением с учителем, а не только алгоритмы распознавания образов без учителя. Также, колонка Class пригодится для оценки результатов любых типов алгоритмов.\n",
    "\n",
    "Изучаем описательные статистики и диаграммы:\n",
    "- описательные статистики: creditcard_Descriptives.html (*HTML файл был получен с помощью приложения: Jamovi*);\n",
    "- гистограммы: creditcard_Histograms.pdf;\n",
    "- ящики с усами: creditcard_BoxPlots.pdf.\n",
    "\n",
    "(*PDF файлы был получены с помощью скриптов R + пакет tidyverse, проект RStudio со скриптами находится в подкаталоге: DiagramsInR.*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72e2ac5-eb1b-44e4-abd6-e44bd15c57a3",
   "metadata": {},
   "source": [
    "## Выводы по описательным статистикам и диаграммам\n",
    "\n",
    "Признак Time не будем использовать, чтобы модели не переобучились по ней как по уникальному идентификатору.\n",
    "\n",
    "Пропущенных значений в колонках нет.\n",
    "\n",
    "Процент аномалий, подсчитанный по переменной Class: 492 / (492 + 284315) = 0.17 %. Аномалии это редкое явление в данном dataset.\n",
    "\n",
    "По гистограммам видно, что распределения достаточно симметричные, близки к нормальному (более резкие, чем нормальное).\n",
    "\n",
    "По гистограмма и по ящикам с усами видно, что есть много выбросов — значительная часть данных находится в выбросах.\n",
    "\n",
    "Колонки имеют сильно разный диапазон значений, поэтому нужно нормировать данные. В данных много выбросов, поэтому применим более устойчивый к выбросам метод нормализации: RobustScaler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05705b8-e6d1-4e8c-85f4-4f9363afef48",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "1. Удаляем колонку Time.\n",
    "2. Остальные колонки, кроме Class, нормируем с помощью: RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5daacd1-f076-4a73-8e95-eb6b8c3fab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "df = pd.read_csv(r'.\\creditcard.csv')\n",
    "df = df.drop(columns='Time', axis=1)\n",
    "\n",
    "columns_for_scaling = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\n",
    "                       \"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\n",
    "                       \"Amount\"]\n",
    "scaler = RobustScaler()\n",
    "df[columns_for_scaling] = scaler.fit_transform(df[columns_for_scaling])\n",
    "\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209cfc8-6808-4030-9563-eebebea2ac2d",
   "metadata": {},
   "source": [
    "Теперь разобьем набор данных на тренировочную и тестовую выборку со стратификацией по переменной-метке (Class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302f74ed-a084-409c-b300-c47ceb5b2634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('Class', axis=1),\n",
    "    df['Class'],\n",
    "    test_size=0.2,\n",
    "    stratify=df['Class'],\n",
    "    random_state=1)\n",
    "\n",
    "# Save training set\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv(r'.\\creditcard_train.csv', index=False)\n",
    "\n",
    "# Save testing set\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv(r'.\\creditcard_test.csv', index=False)\n",
    "\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea78e46-52c9-4722-ac19-37822d777701",
   "metadata": {},
   "source": [
    "- Подготовленный для тренировки моделей dataset находится в файле creditcard_train.csv\n",
    "- Тестовый dataset находится в файле creditcard_test.csv\n",
    "\n",
    "Можем переходить к моделированию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd82337-8d69-41fd-b5f4-407054499149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
