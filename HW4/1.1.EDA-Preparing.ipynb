{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffd4856-b3a8-4f04-ba68-2e50619beb8b",
   "metadata": {},
   "source": [
    "# EDA and Preparing\n",
    "\n",
    "Используем набор данных https://www.kaggle.com/datasets/vikalpdongre/us-flights-data-2008\n",
    "\n",
    "Есть пропуски в колонке ArrTime: ≈ 2 %, поэтому удалим записи с пропусками. (Таблица с пропусками прилагается в файле 2008_Descriptives.pdf. Файл PDF получен с помощью программы Jamovi.)\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Для симуляции нам нужны следующие колонки:\n",
    "- Year\n",
    "- Month\n",
    "- DayofMonth\n",
    "- ArrTime — время прибытия\n",
    "- Origin — откуда вылет\n",
    "- Dest — куда прилетели.\n",
    "\n",
    "Набор данных неупорядоченный, в нем есть перемешанные по времени события, поэтому нужна сортировка.\n",
    "\n",
    "Поэтому для симуляции:\n",
    "1. Создадим dummy-variable DateTime = Year + Month + DayofMonth + ArrTime.\n",
    "2. Запишем отсортированный по DateTime набор данных в выходной файл с колонками:\n",
    "    - Origin\n",
    "    - Dest\n",
    "    - DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c70805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "column_names = ['Year', 'Month', 'DayofMonth', 'Origin', 'Dest', 'ArrTime']\n",
    "\n",
    "def create_date(row):\n",
    "    is_next_day = False\n",
    "    hm = str(int(row['ArrTime'])).zfill(4)\n",
    "    hours, minuts = int(hm[:2]), int(hm[2:])\n",
    "\n",
    "    if hours >= 24:\n",
    "        hours = hours - 24\n",
    "        is_next_day = True\n",
    "\n",
    "    result = datetime(int(row['Year']), int(row['Month']), int(row['DayofMonth']), int(hours), int(minuts))\n",
    "\n",
    "    if is_next_day:\n",
    "        result = result + timedelta(days=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "chunksize = 20000\n",
    "for i, chunk in enumerate(pd.read_csv('2008.csv', chunksize=chunksize, iterator=True, usecols=column_names)):\n",
    "    chunk = chunk.dropna(subset=['ArrTime'])\n",
    "    chunk['DateTime'] = chunk.apply(create_date, axis=1)\n",
    "    chunk = chunk.drop(columns=['Year','Month', 'DayofMonth', 'ArrTime'])\n",
    "    chunk.to_csv('2008_with_date.csv', mode=(i == 0 and 'w' or 'a'), header=(i == 0), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da718797",
   "metadata": {},
   "source": [
    "Выполним сортировку как описано в https://stackoverflow.com/questions/21271727/sorting-in-pandas-for-large-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1e9550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine # database connection \n",
    "\n",
    "\n",
    "path_to_db = '2008.db'\n",
    "\n",
    "if os.path.isfile(path_to_db):\n",
    "    os.remove(path_to_db)\n",
    "\n",
    "disk_engine = create_engine('sqlite:///'+path_to_db) # Initializes an database in current directory\n",
    "\n",
    "chunksize = 20000\n",
    "index_start = 1\n",
    "\n",
    "for chunk in pd.read_csv('2008_with_date.csv', chunksize=chunksize, iterator=True, encoding='utf-8'):\n",
    "    chunk.index += index_start\n",
    "    chunk.to_sql('data', disk_engine, if_exists='append')\n",
    "    index_start = chunk.index[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5655a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine # database connection \n",
    "\n",
    "\n",
    "disk_engine = create_engine('sqlite:///'+path_to_db) # The Connection to the DB\n",
    "\n",
    "df = pd.read_sql_query('SELECT * '\n",
    "                       'FROM data '\n",
    "                       'ORDER BY DateTime ',\n",
    "                       #'LIMIT 10', \n",
    "                       disk_engine)\n",
    "df = df.drop(columns=('index'))\n",
    "\n",
    "combined_list = np.concatenate((df['Origin'], df['Dest']))\n",
    "unique_values_as_string = reduce(lambda a, s: a + ', ' + s, np.unique(combined_list))\n",
    "with open('2008_cityNames.txt', 'wt') as file_out:\n",
    "    file_out.write(unique_values_as_string)\n",
    "\n",
    "with open('2008_numberOfRecords.txt', 'wt') as file_out:\n",
    "    file_out.write(str(len(df)))\n",
    "\n",
    "with open('2008_firstDateTime.txt', 'wt') as file_out:\n",
    "    file_out.write(df.loc[0, 'DateTime'])\n",
    "\n",
    "df.to_csv('2008_with_date_sorted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff775f2b",
   "metadata": {},
   "source": [
    "Сохранили:\n",
    "- список уникальных имен городов (коды аэропортов) в файл 2008_cityNames.txt;\n",
    "- самую раннюю дату-время (для старта симуляции) 2008_firstDateTime.txt;\n",
    "- объем набора данных 2008_numberOfRecords.txt;\n",
    "- отсортированный по дате файл с перелётами 2008_with_date_sorted.csv .\n",
    "\n",
    "**Теперь мы готовы перейти к симуляции.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da06ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
