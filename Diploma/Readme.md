Otus ML Pro 2024 — Проектная работа
===================================

1. Выбрать тему: <a href="Кастомная категория акций.pdf">Кастомная категория биржевых акций.</a>

2. Собрать, проанализировать и предобработать данные.
    - Загрузка данных [2.LoadDataset.ipynb](2.LoadDataset.ipynb)
Результат: shares_dataset.csv
    - Пользователь разбивает набор данных на train, test и проставляет метки в колонке label.

Для примера подготовлен набор данных для отбора акций отечественных компаний, которые интенсивно используют или развивают технологии ИИ и/или генетику.

``` Результат:
        - shares_detector_train.csv — тренировочный набор данных с метками (*пользователь может использовать не весь исходный набор данных*)
        - shares_detector_test.csv — тестовый набор данных с метками (*набор данных маленький и несбалансированный*)
        - importantWords.csv — пользователь может добавить в тренировку редкие, но, возможно, важные для классификации слова
        - stopWords.txt — список стоп-слов (основа взята с сайта <a href="https://snipp.ru/seo/stop-ru-words">https://snipp.ru/seo/stop-ru-words</a>), пользователь может отредактировать список, например, добавить встречающиеся в наборе данных названия компаний
```

3. Построить первые baseline модели (использованы инструменты: R 4.3.3, RStudio).

Почему R?
- Многие специалисты владеют R.  Навык R даст возможность лучше коммуницировать в команде.
- Прототипирование на R быстрее, чем на Python.

*Модель 0*: была попытка использовать Naive Bayes модель: неудачно, результат низкий. <a href="3.1. Тренировка модели\TestResultsWithnaiveBayesOnRStudio.png">"3.1. Тренировка модели\TestResultsWithnaiveBayesOnRStudio.png"</a>

*Модель 1*: RandomForest [baseline модель](Baseline model.pdf) (результат хороший).
3.1. Тренировка модели. Для тренировки использованы файлы: shares_detector_train.csv, shares_detector_test.csv, importantWords.csv, stopWords.txt и файлы из подкаталога "3.1. Тренировка модели".

Список стоп-слов можно использовать двояко:
    - добавить в список названия компаний, чтобы модель не переобучалась;
    - но пользователь может решить специально добавить в результаты акции, связанные с определенной компанией, тогда название данной компании становится не идентификатором, а целевым термином, как бы, такие целевые слова в список стоп-слов не будут вноситься.

Исходный код тренировки модели: "3.1. Тренировка модели\TrainDetector.R". (Содержит код тренировки текущей модели Random Forest, также закомментированный код для Naive Bayes модели, также, закомментированный код для построения диаграмм "облако слов".)

    Результат:
        - Cohen's Kappa Train: 0.969, Test: 1, AUC-ROC: 1 (набор данных очень маленький, поэтому результат нельзя трактовать прямо, как 100 % качество модели, но практическое использование показало, что результат хороший). "3.1. Тренировка модели\TestResultsOnRStudio.png"
        - dtm_df_columns.csv — содержит сохраненный, по результатам тренировки, набор колонок Document-Term-Matrix, чтобы при inference воспроизвести структуру матрицы (как было при обучении).
        - `20250105model_R4.3.3_randomForest4.7-1.1.RData` — сериализованная обученная модель

*Модель 2*: RandomForest — тренировка выполнена аналогично модели 1, но по алгоритму кросс-валидации
    Результат:
        - Cohen's Kappa Train: 0.969, Test: 1, AUC-ROC: 1 (значительного улучшения не получено, чуть «прямее» выглядит график AUC-ROC, но это на пределе точности измерения). "3.1. Тренировка модели\TestResultsWithCrossValidationOnRStudio.png"
"3.1. Тренировка модели\TrainDetectorWithCrossValidation.R"
        - dtm_df_columns.csv — содержит сохраненный, по результатам тренировки, набор колонок Document-Term-Matrix, чтобы при inference воспроизвести структуру матрицы (как было при обучении).
        - `20250109model_R4.3.3_randomForest4.7-1.1` — сериализованная обученная модель

Метод тренировки с кросс-валидацией был взят из статьи: https://rstudio-pubs-static.s3.amazonaws.com/868139_8b884a6b86fa4081981d2efe5218f6f6.html

3.2. Использование модели (inference).

    Для работы inference используются файлы: 
        - stopWords.txt — список стоп-слов для предобработки входных текстов;
        - "3.1. Тренировка модели\dtm_df_columns.csv" — содержит сохраненный, по результатам тренировки, набор колонок Document-Term-Matrix, чтобы при inference воспроизвести структуру матрицы (как было при обучении);
        - `*model_R4.3.3_randomForest4.7-1.1.RData` — сериализованная обученная модель.

    Исходный код приложения: 
        - runPlumber.R — стартовый модуль REST JSON WebAPI (Plumber), в файле прописан порт на котором будет принимать соединения WebAPI;
        - predict.R — модуль с исходным кодом приложения;
        - Dockerfile — для сборки приложения в докер-контейнере, использование менеджера пакетов pak дало высокую скорость сборки контейнера.

7. Презентовать проект, рассказать о своем исследовании, что вы сделали, каких результатов добились.
[Кастомная категория биржевых акций.](Кастомная категория акций.pdf)

Результат

Использование модели позволяет:
    - расширить число акций в активе, потому что модель фильтрует акции беспристрастно и внимательно с высоким покрытием, исключается человеческий фактор;
    - исследовать рынок по выбранному категориальному критерию, потому что модель может «заметить» акции, на которые не обратил внимание человек (например, в случаях, когда неочевидно, что акция на самом деле подходит под критерии, а модель такие случаи может обнаружить) и привести к некоторым «открытиям»;
    - также, модель экономит время при многократном/периодическом использовании inference, потому что человеку пришлось бы неоднократно просматривать и анализировать информацию по всем акциям, на такую работу ушло бы больше времени. 

«Лишние акции», которые может выдать модель в результатах, не являются критической проблемой в данной предметной области (в отличие от медицины, например), потому что они не приводят бизнес к краху (при наличии диверсификации и на других акциях тоже, возможно, получится заработать). Пользователь может легко заметить явно неподходящие акции самостоятельно или добавить дополнительный фильтр на вход: удалять из входного запроса записи с пустым описанием.

Пример запроса и ответа находится в подкаталоге "3.2. Docker app\Test Inference" (отбор компаний, которые вкладываются в технологии ИИ и/или генетические). 

Мы видим, что модель хорошо отобрала целевые компании — в результатах есть подходящие компании, которых не было в тренировочном наборе данных.




