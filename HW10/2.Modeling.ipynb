{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficient_apriori\n",
    "!pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from typing import Dict\n",
    "\n",
    "import implicit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from efficient_apriori import apriori\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\" Зафиксируем seed для воспроизводимости \"\"\"\n",
    "    random.seed(seed) # Фиксируем генератор случайных чисел\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # Фиксируем заполнения хешей\n",
    "    np.random.seed(seed) # Фиксируем генератор случайных чисел numpy\n",
    "\n",
    "\n",
    "def df_to_lists_basic(df: pd.DataFrame,\n",
    "                      is_add_ratings: False) -> tuple[list, dict, dict]:\n",
    "    votes_by_users = {}\n",
    "    ratings_by_users = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row['user'] in votes_by_users:\n",
    "           votes_by_users[row['user']].append(row['item'])\n",
    "\n",
    "           if is_add_ratings:\n",
    "               ratings_by_users[row['user']].append(row['rating'])\n",
    "        else:\n",
    "           votes_by_users[row['user']] = [row['item']]\n",
    "\n",
    "           if is_add_ratings:\n",
    "               ratings_by_users[row['user']] = [row['rating']]\n",
    "\n",
    "    itemsets_list = [\n",
    "        items_list for items_list in votes_by_users.values()\n",
    "        if len(items_list) > 1\n",
    "    ]\n",
    "\n",
    "    if not is_add_ratings:\n",
    "        return itemsets_list, votes_by_users, None\n",
    "    else:\n",
    "        return itemsets_list, votes_by_users, ratings_by_users\n",
    "\n",
    "\n",
    "def df_to_lists(df: pd.DataFrame) -> tuple[list, dict]:\n",
    "    itemsets_list, votes_by_users, _ = df_to_lists_basic(\n",
    "        df,\n",
    "        is_add_ratings=False\n",
    "    )\n",
    "    return itemsets_list, votes_by_users\n",
    "    \n",
    "\n",
    "def df_to_lists_with_ratings(df: pd.DataFrame) -> tuple[list, list]:\n",
    "    itemsets_list, votes_by_users, ratings_by_users = df_to_lists_basic(\n",
    "        df,\n",
    "        is_add_ratings=True\n",
    "    )\n",
    "    return itemsets_list, list(zip(votes_by_users, ratings_by_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             user        item  rating\n",
      "0  A18A2Q0UNZU1LQ  B00FFINUJK     5.0\n",
      "1  A1U9LTA3EWSNY1  B00006OAQU     5.0\n",
      "2  A1KJ94X41TJLX0  B00005JYC3     5.0\n",
      "3  A2ZRNN0L6XI9AM  B000Z3DXT2     5.0\n",
      "4  A2QQR1OJE3YDH1  B00002R2AC     5.0\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\".//train.csv\")\n",
    "df_test = pd.read_csv(\".//test.csv\")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "В качестве baseline используем модель, которая рекомендует самые популярные товары. Мы зададим гиперпараметр n — top сколько товаров использовать. Модель будет рекомендовать n самых популярных товаров с использованием генератора псевдослучайных чисел с учётом частот встречаемости данных товаров (более популярные товары будут рекомендоваться статистически чаще, чем менее популярные)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent_items(df:pd.core.frame.DataFrame,\n",
    "                            min_level:float,\n",
    "                            n:int) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Get the most frequent items with rating min_level at least.\n",
    "\n",
    "    Args:\n",
    "        df (pandas DataFrame): dataframe;\n",
    "        min_level (float): минимальный уровень rating для набора данных\n",
    "        n (int): number of the most frequent items.\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame for records where rating is more\n",
    "    # or equals than min_level.\n",
    "    df_score_n = df[df['rating'] >= min_level]\n",
    "\n",
    "    # Count the frequency of each unique item in the 'item' column.\n",
    "    frequency_df = df_score_n['item'].value_counts()\n",
    "\n",
    "    # Get the top 'n' most frequent items.\n",
    "    most_frequent_items = frequency_df.head(n)\n",
    "\n",
    "    result = {\n",
    "        item: most_frequent_items[item] for item in most_frequent_items.index\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_random_item_by_frequency(frequent_items_as_dict:Dict[str, int]):\n",
    "    total = sum(list(frequent_items_as_dict.values()))\n",
    "    scale_k = 1.0 / total\n",
    "    values = list(frequent_items_as_dict.values())\n",
    "    chosen_item = random.choices(\n",
    "        list(frequent_items_as_dict.keys()),\n",
    "        k=1,\n",
    "        weights=[freq * scale_k for freq in values]\n",
    "    )\n",
    "    return chosen_item[0]\n",
    "\n",
    "\n",
    "class BaselineModel:\n",
    "    \"\"\"\n",
    "    Baseline Model которая рекомендует самые популярные товары\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 df:pd.core.frame.DataFrame,\n",
    "                 min_level:float,\n",
    "                 n:int):\n",
    "        \"\"\"\n",
    "        Baseline Model\n",
    "\n",
    "        Args:\n",
    "            df (pandas DataFrame): dataframe for training.\n",
    "            min_level (float): минимальный уровень rating для набора данных.\n",
    "            n (int): number of the most frequent items (hyperparameter)\n",
    "        Returns:\n",
    "            Instance of BaselineModel (BaselineModel)\n",
    "        \"\"\"\n",
    "        self._df_frequent_items = get_most_frequent_items(df, min_level, n)\n",
    "        print(\"The most frequent items\", self._df_frequent_items, sep='\\n')\n",
    "    \n",
    "    def infer(self) -> str:\n",
    "        \"\"\" Inference \"\"\"\n",
    "        return get_random_item_by_frequency(self._df_frequent_items)\n",
    "\n",
    "\n",
    "def add_preds_baseline_to_df(model: BaselineModel, df: pd.DataFrame, k: int):\n",
    "    \"\"\" Add preds from baseline model to test dataframe \"\"\"\n",
    "    print(\"Calculate baseline preds, k =\", k)\n",
    "    preds = []\n",
    "    for _ in range(len(df)):\n",
    "        preds.append([model.infer() for _ in range(k)])\n",
    "\n",
    "    df['preds_baseline'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent items\n",
      "{'B00H9A60O4': 2837, 'B00NG7JVSQ': 2543, 'B00CTTEKJW': 2463, 'B00UB76290': 2334, 'B00EZPXYP4': 1949, 'B00EZQYC8G': 1142, 'B00E6LJ2SA': 1104, 'B000HCZ8EO': 1033, 'B0064PFB9U': 985, 'B00F8K9MZQ': 954}\n"
     ]
    }
   ],
   "source": [
    "model_baseline = BaselineModel(df_train, min_level=5.0, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики\n",
    "\n",
    "Оцените качество полученных рекомендаций по метрикам HR@10 (Hit Rate), MRR@10 (mean reciprocal rank), NDCG@10 (normalized discounted cumulative gain), coverage (recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(df: pd.DataFrame, pred_col='preds', true_col='true') -> float:\n",
    "    \"\"\" Calculate HR metric \"\"\"\n",
    "    hr_values = []\n",
    "    for _, row in df.iterrows():\n",
    "        hr_values.append(int(row[true_col] in row[pred_col]))\n",
    "    return np.mean(hr_values)\n",
    "\n",
    "\n",
    "def recall(df: pd.DataFrame, pred_col='preds', true_col='true') -> float:\n",
    "    \"\"\" Calculate Recall metric \"\"\"\n",
    "    coverage_data = {}\n",
    "    for _, row in df.iterrows():\n",
    "        is_ok_as_int = int(row[true_col] in row[pred_col])\n",
    "        if row['user'] in coverage_data:\n",
    "           coverage_data[row['user']].append(is_ok_as_int)\n",
    "        else:\n",
    "           coverage_data[row['user']] = [is_ok_as_int]\n",
    "    \n",
    "    return np.mean(\n",
    "       [sum(values) / len(values) for values in list(coverage_data.values())]\n",
    "    )\n",
    "\n",
    "\n",
    "def mrr(df: pd.DataFrame, pred_col='preds', true_col='true') -> float:\n",
    "    \"\"\" Calculate MRR metric \"\"\"\n",
    "    mrr_values = []\n",
    "    for _, row in df.iterrows():\n",
    "      try:\n",
    "        user_mrr = 1 / (row[pred_col].index(row[true_col]) + 1)\n",
    "      except ValueError:\n",
    "        user_mrr = 0\n",
    "      mrr_values.append(user_mrr)\n",
    "    return np.mean(mrr_values)\n",
    "\n",
    "\n",
    "def ndcg(df: pd.DataFrame, pred_col='preds', true_col='true') -> float:\n",
    "    \"\"\"\n",
    "    Calculate NDCG metric\n",
    "     ideal dcg == 1 при стратегии разделения leave-one-out\n",
    "    \"\"\"\n",
    "    ndcg_values = []\n",
    "    for _, row in df.iterrows():\n",
    "      try:\n",
    "        user_ndcg = 1 / np.log2(row[pred_col].index(row[true_col]) + 2)\n",
    "      except ValueError:\n",
    "        user_ndcg = 0\n",
    "      ndcg_values.append(user_ndcg)\n",
    "    return np.mean(ndcg_values)\n",
    "\n",
    "  \n",
    "def print_metrics(df: pd.DataFrame, pred_col):\n",
    "    print(\"HR@10 =   \",\n",
    "          f\"{hr(df, pred_col=pred_col, true_col='item'):.3f}\")\n",
    "    print(\"MRR@10 =  \",\n",
    "          f\"{mrr(df, pred_col=pred_col, true_col='item'):.3f}\")\n",
    "    print(\"NDCG@10 = \",\n",
    "          f\"{ndcg(df, pred_col=pred_col, true_col='item'):.3f}\")\n",
    "    print(\"recall =  \",\n",
    "          f\"{recall(df, pred_col=pred_col, true_col='item'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики baseline модели\n",
    "\n",
    "Результаты predictions добавим в df_test в виде отдельной колонки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate baseline preds, k = 10\n",
      "             user        item  rating  \\\n",
      "0  A18A2Q0UNZU1LQ  B00FFINUJK     5.0   \n",
      "1  A1U9LTA3EWSNY1  B00006OAQU     5.0   \n",
      "2  A1KJ94X41TJLX0  B00005JYC3     5.0   \n",
      "3  A2ZRNN0L6XI9AM  B000Z3DXT2     5.0   \n",
      "4  A1DTOHMM2Y5KY0  B00009Q6KO     5.0   \n",
      "\n",
      "                                      preds_baseline  \n",
      "0  [B00NG7JVSQ, B00H9A60O4, B00UB76290, B00NG7JVS...  \n",
      "1  [B00NG7JVSQ, B00CTTEKJW, B00H9A60O4, B00UB7629...  \n",
      "2  [B00CTTEKJW, B00CTTEKJW, B00CTTEKJW, B00H9A60O...  \n",
      "3  [B000HCZ8EO, B00UB76290, B00UB76290, B00H9A60O...  \n",
      "4  [B00UB76290, B00UB76290, B00UB76290, B000HCZ8E...  \n"
     ]
    }
   ],
   "source": [
    "add_preds_baseline_to_df(model_baseline, df_test, k=10)\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@10 =    0.091\n",
      "MRR@10 =   0.038\n",
      "NDCG@10 =  0.051\n",
      "recall =   0.092\n"
     ]
    }
   ],
   "source": [
    "print_metrics(df_test, 'preds_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori\n",
    "\n",
    "Воспользуемся готовой имплементацией алгоритма apriori из библиотеки efficient_apriori.<br />\n",
    "Нам нужно будет сделать оценку по метрикам k = 10, поэтому будем генерировать по 10 рекомендаций для каждого пользователя из test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_preds_apriori_to_df(\n",
    "        votes_by_users: dict,\n",
    "        df: pd.DataFrame,\n",
    "        rules: list,\n",
    "        pred_col: str,\n",
    "        baseline_model: BaselineModel,\n",
    "        limit: int):\n",
    "    \"\"\" Вычислим predictions для заданного dataset и добавим как колонку \n",
    "    в этот же dataset.\n",
    "    Если в конкретном случае не будет подобрано достаточно рекомендаций\n",
    "    по правилам Apriori,\n",
    "    то будет использована рекомендация от Baseline Model.\n",
    "    \"\"\"\n",
    "    results_column = []\n",
    "    # Для каждого пользователя из заданного dataset:\n",
    "    for user in tqdm(df['user']):\n",
    "        if user in votes_by_users:\n",
    "            # возьмём историю покупок из train dataset\n",
    "            items = votes_by_users[user]\n",
    "            # добавим в результат рекомендации \n",
    "            # из всех подошедших правил Apriori\n",
    "            predicts = set()\n",
    "            for r in rules:\n",
    "                if set(r.lhs).issubset(items):\n",
    "                    predicts.update(r.rhs)\n",
    "\n",
    "            # Оставляем в predicts только те товары, которые пользователь\n",
    "            # ещё не купил в train dataset.\n",
    "            predicts.difference_update(items)\n",
    "\n",
    "        # Если нет такого пользователя в train dataset\n",
    "        # или не удалось найти достаточное кол-во рекомендаций по\n",
    "        # подходящим правилам Apriori,\n",
    "        # то вставим в predicts рекомендации от Baseline Model.\n",
    "        predicts_as_list = list(predicts)\n",
    "        if len(predicts) < limit:\n",
    "            for _ in range(limit - len(predicts)):\n",
    "                predicts_as_list.append(baseline_model.infer())\n",
    "\n",
    "        results_column.append(predicts_as_list[:limit])\n",
    "\n",
    "    df[pred_col] = results_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для рекомендаций нам интересны только положительные оценки. Поэтому, оставим все записи с оценками 5 баллов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ok = df_train[df_train['rating'] >= 5.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сконвертируем данные в формат списков для обучения модели apriori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число списков связанных приобретений товаров: 5313\n",
      "[['B00002S7GO', 'B00005JYC6', 'B009HBCU9W'], ['B00003IRBV', 'B00003IRBU'], ['B00002S7GR', 'B00002S7GO', 'B00004NHN0', 'B00002S7GN', 'B00004YUG3'], ['B000023VU1', 'B000Z3DXT2'], ['B000029714', 'B00002S8QS', 'B00002S8QU', 'B00004W62O', 'B00004ZD8I', 'B00006BN8J', 'B000066TPC']]\n"
     ]
    }
   ],
   "source": [
    "lists_train, votes_by_users_train = df_to_lists(df_ok)\n",
    "print(\"Число списков связанных приобретений товаров:\", len(lists_train))\n",
    "print(lists_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsets, rules = list(apriori(\n",
    "    lists_train,\n",
    "    min_support=0.0003,\n",
    "    min_confidence=0.25,\n",
    "    max_length=20\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правил: 2711\n",
      "Примеры:\n",
      "('B003VMCBEC',) → ('0321700945',); \tsupport = 0.000; confidence = 0.400; lift = 354.200\n",
      "('0321700945',) → ('B003VMCBEC',); \tsupport = 0.000; confidence = 0.333; lift = 354.200\n",
      "('1413313728',) → ('B009SPCTFW',); \tsupport = 0.000; confidence = 0.250; lift = 102.173\n",
      "('B00CG0CL1S',) → ('1413313728',); \tsupport = 0.000; confidence = 0.250; lift = 166.031\n",
      "('1413313728',) → ('B00CG0CL1S',); \tsupport = 0.000; confidence = 0.250; lift = 166.031\n",
      "('B001259DRI',) → ('B000FJSA2G', 'B000FQ9R9O', 'B000HKIM7Q', 'B000MVJZGM', 'B00125DG8K'); \tsupport = 0.000; confidence = 1.000; lift = 2656.500\n",
      "('B000MVJZGM',) → ('B000FJSA2G', 'B000FQ9R9O', 'B000HKIM7Q', 'B001259DRI', 'B00125DG8K'); \tsupport = 0.000; confidence = 1.000; lift = 2656.500\n",
      "('B000HKIM7Q',) → ('B000FJSA2G', 'B000FQ9R9O', 'B000MVJZGM', 'B001259DRI', 'B00125DG8K'); \tsupport = 0.000; confidence = 0.333; lift = 885.500\n",
      "('B000FQ9R9O',) → ('B000FJSA2G', 'B000HKIM7Q', 'B000MVJZGM', 'B001259DRI', 'B00125DG8K'); \tsupport = 0.000; confidence = 1.000; lift = 2656.500\n",
      "('B000FJSA2G',) → ('B000FQ9R9O', 'B000HKIM7Q', 'B000MVJZGM', 'B001259DRI', 'B00125DG8K'); \tsupport = 0.000; confidence = 0.286; lift = 759.000\n"
     ]
    }
   ],
   "source": [
    "LEVEL_APRIORI_LIFT = 2.0\n",
    "\n",
    "# Оставляем только правила с lift не меньше заданного порога\n",
    "rules = list(filter(lambda r: r.lift >= LEVEL_APRIORI_LIFT, rules))\n",
    "\n",
    "print(\"Правил:\", len(rules))\n",
    "\n",
    "print(\"Примеры:\")\n",
    "for r in rules[:5] + rules[-5:]:\n",
    "    print(r.lhs, \"→\", r.rhs, end='; \\t')\n",
    "    print(f\"support = {r.support:.3f}\", end='; ')\n",
    "    print(f\"confidence = {r.confidence:.3f}\", end='; ')\n",
    "    print(f\"lift = {r.lift:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим тестовые predictions с использованием правил Apriori, которые мы получили по тренировочному dataset.<br />\n",
    "Если для какого-то пользователя не удастся найти подходящих правил Apriori или кол-во рекомендаций по правилам Apriori будет недостаточно, то вставим в predicts рекомендацию от Baseline Model. Для этого передадим ссылку на Baseline Model во входных аргументах функции add_preds_apriori_to_df.<br />\n",
    "Результаты predictions добавим в df_test в виде отдельной колонки.<br />\n",
    "Параметр limit позволяет задать кол-во рекомендаций для каждого пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26557/26557 [00:13<00:00, 2023.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             user        item  rating  \\\n",
      "0  A18A2Q0UNZU1LQ  B00FFINUJK     5.0   \n",
      "1  A1U9LTA3EWSNY1  B00006OAQU     5.0   \n",
      "2  A1KJ94X41TJLX0  B00005JYC3     5.0   \n",
      "3  A2ZRNN0L6XI9AM  B000Z3DXT2     5.0   \n",
      "4  A1DTOHMM2Y5KY0  B00009Q6KO     5.0   \n",
      "\n",
      "                                       preds_apriori  \n",
      "0  [B00FFINOWS, B00EZPXYP4, B00H9A60O4, B00CTTEKJ...  \n",
      "1  [B000A6M8QI, B000050HEI, B00CTTEKJW, B00CTTEKJ...  \n",
      "2  [B00UB76290, B00UB76290, B00NG7JVSQ, B00NG7JVS...  \n",
      "3  [B00006BN8P, B00002S6GE, B00002S6E4, B00004NHK...  \n",
      "4  [B0000E3QNB, B00NG7JVSQ, B00EZPXYP4, B00NG7JVS...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "add_preds_apriori_to_df(\n",
    "    votes_by_users_train,\n",
    "    df_test,\n",
    "    rules,\n",
    "    \"preds_apriori\",\n",
    "    model_baseline,\n",
    "    limit=10\n",
    ")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@10 =    0.110\n",
      "MRR@10 =   0.065\n",
      "NDCG@10 =  0.076\n",
      "recall =   0.111\n"
     ]
    }
   ],
   "source": [
    "print_metrics(df_test, 'preds_apriori')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope One\n",
    "\n",
    "В качестве эксперимента проверим модель Slope One http://www.serpentine.com/blog/2006/12/12/collaborative-filtering-made-easy/ <br />\n",
    "Реализация взята и адаптирована из Интернет: https://github.com/kek/slopeone/tree/master \n",
    "\n",
    "Slope One модель учится и делает predict по полному диапазону оценок (не только по оценкам 5) (внутри модели оценки представляются в диапазоне [0; 1], это учтено в функциях ниже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2006 Bryan O'Sullivan <bos@serpentine.com>.\n",
    "#\n",
    "# This software may be used and distributed according to the terms\n",
    "# of the GNU General Public License, version 2 or later, which is\n",
    "# incorporated herein by reference.\n",
    "# 10.03.2025 the updated version for python 3 syntax.\n",
    "\n",
    "class SlopeOne(object):\n",
    "    def __init__(self):\n",
    "        self.diffs = {}\n",
    "        self.freqs = {}\n",
    "\n",
    "    def predict(self, userprefs):\n",
    "        preds, freqs = {}, {}\n",
    "        for item, rating in userprefs.items():\n",
    "            for diffitem, diffratings in self.diffs.items():\n",
    "                try:\n",
    "                    freq = self.freqs[diffitem][item]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                preds.setdefault(diffitem, 0.0)\n",
    "                freqs.setdefault(diffitem, 0)\n",
    "                preds[diffitem] += freq * (diffratings[item] + rating)\n",
    "                freqs[diffitem] += freq\n",
    "        return dict([(item, value / freqs[item])\n",
    "                     for item, value in preds.items()\n",
    "                     if item not in userprefs and freqs[item] > 0])\n",
    "\n",
    "    def update(self, userdata):\n",
    "        for ratings in userdata.values():\n",
    "            for item1, rating1 in ratings.items():\n",
    "                self.freqs.setdefault(item1, {})\n",
    "                self.diffs.setdefault(item1, {})\n",
    "                for item2, rating2 in ratings.items():\n",
    "                    self.freqs[item1].setdefault(item2, 0)\n",
    "                    self.diffs[item1].setdefault(item2, 0.0)\n",
    "                    self.freqs[item1][item2] += 1\n",
    "                    self.diffs[item1][item2] += rating1 - rating2\n",
    "        for item1, ratings in self.diffs.items():\n",
    "            for item2 in ratings:\n",
    "                ratings[item2] /= self.freqs[item1][item2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dicts(df: pd.DataFrame, max_rating: int=5.0):\n",
    "    results = dict()\n",
    "    for _, row in df.iterrows():\n",
    "        if row['user'] in results:\n",
    "            results['user'][row['item']] = row['rating'] / max_rating\n",
    "        else:\n",
    "            results['user'] = { row['item']: row['rating'] / max_rating }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_preds_slopeone_to_df(\n",
    "        votes_by_users: dict,\n",
    "        df: pd.DataFrame,\n",
    "        pred_col: str,\n",
    "        slopeone_model: SlopeOne,\n",
    "        baseline_model: BaselineModel,\n",
    "        limit: int):\n",
    "    \"\"\" Вычислим predictions для заданного dataset и добавим как колонку \n",
    "    в этот же dataset.\n",
    "    Если в конкретном случае не будет подобрано достаточно рекомендаций,\n",
    "    то будет использована рекомендация от Baseline Model.\n",
    "    \"\"\"\n",
    "    results_column = []\n",
    "    # Для каждого пользователя из заданного dataset:\n",
    "    for user in tqdm(df['user']):\n",
    "        predicts_as_set = set()\n",
    "        \n",
    "        if user in votes_by_users:\n",
    "            # возьмём историю покупок из train dataset\n",
    "            items, ratings = votes_by_users[user]\n",
    "\n",
    "            # добавим в результат рекомендации Slope One\n",
    "            inputs = { it: rating / 5.0 for it, rating in zip(items, ratings)}\n",
    "            preds = slopeone_model.predict({ user: inputs })\n",
    "            lst_preds = [it for it, rating in preds.items() if rating > 0.8]\n",
    "            predicts_as_set.update(lst_preds)\n",
    "            # Оставляем в predicts только те товары, которые пользователь\n",
    "            # ещё не купил в train dataset.\n",
    "            predicts_as_set.difference_update(items)\n",
    "\n",
    "        # Если не удалось найти достаточное кол-во рекомендаций,\n",
    "        # то вставим в predicts рекомендации от Baseline Model.\n",
    "        predicts_as_list = list(predicts_as_set)\n",
    "        if len(predicts_as_set) < limit:\n",
    "            for _ in range(limit - len(predicts_as_set)):\n",
    "                predicts_as_list.append(baseline_model.infer())\n",
    "\n",
    "        results_column.append(predicts_as_list[:limit])\n",
    "\n",
    "    df[pred_col] = results_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_train = df_to_dicts(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_slopeone = SlopeOne()\n",
    "model_slopeone.update(dicts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, votes_by_users_train_full = df_to_lists_with_ratings(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54122/54122 [03:29<00:00, 258.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             user        item  rating  \\\n",
      "0  A18A2Q0UNZU1LQ  B00FFINUJK     5.0   \n",
      "1  A1U9LTA3EWSNY1  B00006OAQU     5.0   \n",
      "2  A1KJ94X41TJLX0  B00005JYC3     5.0   \n",
      "3  A2ZRNN0L6XI9AM  B000Z3DXT2     5.0   \n",
      "4  A2QQR1OJE3YDH1  B00002R2AC     5.0   \n",
      "\n",
      "                                      preds_slopeone  \n",
      "0  [B00H9A60O4, B000HCZ8EO, B00EZQYC8G, B00NG7JVS...  \n",
      "1  [B000HCZ8EO, B00CTTEKJW, B00EZQYC8G, B00H9A60O...  \n",
      "2  [B00H9A60O4, B00UB76290, B0064PFB9U, B00CTTEKJ...  \n",
      "3  [B00NG7JVSQ, B00NG7JVSQ, B00NG7JVSQ, B00UB7629...  \n",
      "4  [B00F8K9MZQ, B000HCZ8EO, B00H9A60O4, B00CTTEKJ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "add_preds_slopeone_to_df(\n",
    "    votes_by_users_train_full,\n",
    "    df_test,\n",
    "    \"preds_slopeone\",\n",
    "    model_slopeone,\n",
    "    model_baseline,\n",
    "    limit=10\n",
    ")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@10 =    0.092\n",
      "MRR@10 =   0.036\n",
      "NDCG@10 =  0.049\n",
      "recall =   0.094\n"
     ]
    }
   ],
   "source": [
    "print_metrics(df_test, 'preds_slopeone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS\n",
    "\n",
    "Применим модель на основе матричной факторизации. Необходимо оставить пользователей с количеством купленных товаров не менее 5 (иначе вычисления с матрицей не влезут в ОЗУ и матрица будет с разреженностью ≈ 100 %, что не позволит эффективно работать данному алгоритму.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_sparse_matrix(df: pd.DataFrame):\n",
    "    \"\"\" Convert pandas dataframe to sparse matrix format. \"\"\"\n",
    "    ratings = list(df['rating'])\n",
    "\n",
    "    rows = df['user'].astype('category').cat.codes\n",
    "    cols = df['item'].astype('category').cat.codes\n",
    "\n",
    "    return sparse.csr_matrix(\n",
    "        (ratings, (rows, cols)),\n",
    "        shape=(df['user'].nunique(), df['item'].nunique())\n",
    "    )\n",
    "\n",
    "\n",
    "def get_percent_of_sparsity(sparse_matrix):\n",
    "    \"\"\" Get percent of sparsity from a sparse matrix.\"\"\"\n",
    "    # Number of possible interactions in the matrix\n",
    "    matrix_size = sparse_matrix.shape[0] * sparse_matrix.shape[1]\n",
    "    # Number of items interacted with\n",
    "    num_purchases = len(sparse_matrix.nonzero()[0])\n",
    "    sparsity = 100 * (1 - (num_purchases / matrix_size))\n",
    "    return sparsity\n",
    "\n",
    "\n",
    "def predict_als(train,\n",
    "            user_vecs,\n",
    "            item_vecs,\n",
    "            rating_matrix=None,\n",
    "            filter_seen=False,\n",
    "            k=10):\n",
    "    \"\"\" Get predictions \"\"\"\n",
    "    rows = df_train['user'].astype('category').cat.codes\n",
    "    cols = df_train['item'].astype('category').cat.codes\n",
    "    id2user = dict(zip(rows, train['user']))\n",
    "    id2item = dict(zip(cols, train['item']))\n",
    "\n",
    "    scores = user_vecs.dot(item_vecs.T)\n",
    "    if filter_seen:\n",
    "        scores = np.multiply(\n",
    "            scores,\n",
    "            np.invert(rating_matrix.todense().astype(bool))\n",
    "            )\n",
    "\n",
    "    preds = pd.DataFrame(columns = ['user',\t'preds'])\n",
    "\n",
    "    ind_part = np.argpartition(scores, -k + 1)[:, -k:].copy()\n",
    "    scores_not_sorted = np.take_along_axis(scores, ind_part, axis=1)\n",
    "    ind_sorted = np.argsort(scores_not_sorted, axis=1)\n",
    "    indices = np.take_along_axis(ind_part, ind_sorted, axis=1)\n",
    "    preds = pd.DataFrame({\n",
    "        'user': range(user_vecs.shape[0]),\n",
    "        'preds': np.flip(indices, axis=1).tolist(),\n",
    "        })\n",
    "    preds['user'] = preds['user'].map(id2user)\n",
    "    preds['preds'] = preds['preds'].map(lambda inds: [id2item[i] for i in inds])\n",
    "    return preds\n",
    "\n",
    "\n",
    "def add_preds_als_to_df(\n",
    "        train_df: pd.DataFrame,\n",
    "        df: pd.DataFrame,\n",
    "        sparse_train: sparse._csr.csr_matrix,\n",
    "        pred_col: str,\n",
    "        als_model: implicit.cpu.als.AlternatingLeastSquares,\n",
    "        baseline_model: BaselineModel,\n",
    "        limit: int):\n",
    "    \"\"\" Вычислим predictions для заданного dataset и добавим как колонку \n",
    "    в этот же dataset.\n",
    "    Если в конкретном случае не будет подобрано рекомендаций,\n",
    "    то будет использована рекомендация от Baseline Model.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    vecs_user = als_model.user_factors\n",
    "    vecs_item = als_model.item_factors\n",
    "    # Проверим по размерам, что мы действиельно не перепутали users и items\n",
    "    print(sparse_train.shape)\n",
    "    print(vecs_user.shape, vecs_user.shape)\n",
    "    print(vecs_item.dot(vecs_item.T).shape)\n",
    "\n",
    "    pred = predict_als(\n",
    "                train_df,\n",
    "                vecs_user,\n",
    "                vecs_item,\n",
    "                sparse_train,\n",
    "                filter_seen=True,\n",
    "                k=limit\n",
    "                )\n",
    "    pred = pred.merge(df, how='left', on='user')\n",
    "\n",
    "    print(pred[pred['item'].notna()])\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if len(pred[pred['user'] == row['user']]):\n",
    "            result.append(pred[pred['user'] == row['user']]['preds'].iat[0])\n",
    "        else:\n",
    "            result.append([baseline_model.infer() for _ in range(limit)])\n",
    "\n",
    "    df[pred_col] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_for_train_als(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # создаем список товаров для каждого пользователя\n",
    "    items = df.groupby(['user'], sort=False)['item']\\\n",
    "             .apply(lambda x: list(x)).reset_index()\n",
    "    # создаем список рейтингов для каждого пользователя\n",
    "    ratings = df.groupby(['user'], sort=False)['rating']\\\n",
    "               .apply(lambda x: list(x)).reset_index()\n",
    "    df_grouped = items.merge(ratings)\n",
    "\n",
    "    df_grouped['eq_or_more_5'] = df_grouped['item'].apply(\n",
    "        lambda it: len(it) >= 5\n",
    "    )\n",
    "\n",
    "    df_grouped = df_grouped[df_grouped['eq_or_more_5'] == True]\n",
    "\n",
    "    return df_grouped.explode(['item', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse = df_to_sparse_matrix(filter_df_for_train_als(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity = 99.8 %\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 15826 stored elements and shape (2061, 4881)>\n",
      "  Coords\tValues\n",
      "  (0, 895)\t3.0\n",
      "  (0, 950)\t1.0\n",
      "  (0, 1217)\t3.0\n",
      "  (0, 1249)\t1.0\n",
      "  (0, 1276)\t1.0\n",
      "  (0, 1287)\t1.0\n",
      "  (0, 1983)\t3.0\n",
      "  (1, 2377)\t3.0\n",
      "  (1, 2451)\t6.0\n",
      "  (1, 2459)\t10.0\n",
      "  (1, 2546)\t2.0\n",
      "  (1, 2656)\t5.0\n",
      "  (1, 2704)\t1.0\n",
      "  (1, 2769)\t4.0\n",
      "  (1, 2909)\t5.0\n",
      "  (1, 2919)\t5.0\n",
      "  (1, 2933)\t5.0\n",
      "  (1, 2992)\t1.0\n",
      "  (1, 3022)\t3.0\n",
      "  (1, 3039)\t2.0\n",
      "  (1, 3133)\t5.0\n",
      "  (1, 3199)\t3.0\n",
      "  (1, 3317)\t4.0\n",
      "  (1, 3326)\t3.0\n",
      "  (1, 3469)\t5.0\n",
      "  :\t:\n",
      "  (2056, 4575)\t5.0\n",
      "  (2057, 206)\t2.0\n",
      "  (2057, 238)\t5.0\n",
      "  (2057, 242)\t4.0\n",
      "  (2057, 243)\t4.0\n",
      "  (2057, 255)\t3.0\n",
      "  (2058, 1945)\t5.0\n",
      "  (2058, 1956)\t5.0\n",
      "  (2058, 2068)\t5.0\n",
      "  (2058, 2226)\t5.0\n",
      "  (2058, 2512)\t5.0\n",
      "  (2058, 2514)\t5.0\n",
      "  (2059, 1058)\t1.0\n",
      "  (2059, 1401)\t1.0\n",
      "  (2059, 1826)\t4.0\n",
      "  (2059, 1978)\t1.0\n",
      "  (2059, 2190)\t1.0\n",
      "  (2059, 2569)\t4.0\n",
      "  (2060, 14)\t5.0\n",
      "  (2060, 3278)\t2.0\n",
      "  (2060, 3360)\t3.0\n",
      "  (2060, 3362)\t5.0\n",
      "  (2060, 3384)\t1.0\n",
      "  (2060, 3406)\t1.0\n",
      "  (2060, 3957)\t2.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sparsity = {get_percent_of_sparsity(train_sparse):.1f} %\")\n",
    "print(train_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы фильтрация работала, разреженность должна быть меньше чем приблизительно 99.5%. У нас слишком большая разреженность матрицы (99.8 %), поэтому данный метод в нашем случае не подходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba37c11f84642e58a598597f519b71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_als = implicit.als.AlternatingLeastSquares(factors=32,\n",
    "                                                 regularization=0.1,\n",
    "                                                 iterations=50,\n",
    "                                                 use_gpu=False)\n",
    "model_als.fit((train_sparse).astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2061, 4881)\n",
      "(2061, 32) (2061, 32)\n",
      "(4881, 4881)\n",
      "                user                                              preds  \\\n",
      "63    A1001HS2VA0OYM  [B00005JD6L, B00005LL29, B00005BAJI, B00005MP4...   \n",
      "75    A1005HKYSSJ9L1  [B000067G63, B000089GKU, B00008BX2B, B00008COZ...   \n",
      "102   A100LLXMXDZHJZ  [B00006OAOO, B00008NRUC, B00007LBIO, B000063LG...   \n",
      "105   A100OJ8LFVPMPT  [B00006IKEX, B00006G980, B000053VGC, B00008ACQ...   \n",
      "123   A100WO06OQR8BQ  [B00006HN0G, B0000AZK0Z, B00009APGA, B0000683N...   \n",
      "...              ...                                                ...   \n",
      "1929  A10RTMQISRV7X9  [B00008BX2B, B00009MVMM, B000096L6Y, B00006A6X...   \n",
      "1974  A10SDLX561O4SJ  [B00005JJEV, B00004TZIV, B00005LQSQ, B00005M07...   \n",
      "1979  A10SFBVF41AQJ3  [B0000VYK1Y, B00006IKF5, B00006H34R, B00008NRU...   \n",
      "2026  A10SYDEB3VHO7V  [B00008NRUF, B0000VYK1Y, B00008Z0GB, B0000C4DZ...   \n",
      "2029  A10SZMYAQ2MD8S  [B0000CDVUI, B0000CDZUZ, B000096L6Y, B00006UNS...   \n",
      "\n",
      "            item  rating  \n",
      "63    B00E6LJ2SA     5.0  \n",
      "75    B0013O98SW     5.0  \n",
      "102   B00000JLNZ     5.0  \n",
      "105   B00LC9UU6C     5.0  \n",
      "123   B000AMZLRU     5.0  \n",
      "...          ...     ...  \n",
      "1929  B00UB76290     5.0  \n",
      "1974  B00EZPXYP4     5.0  \n",
      "1979  B0037T8KPI     5.0  \n",
      "2026  B003VIVYF8     5.0  \n",
      "2029  B00EOI2SWC     5.0  \n",
      "\n",
      "[119 rows x 4 columns]\n",
      "             user        item  rating  \\\n",
      "0  A18A2Q0UNZU1LQ  B00FFINUJK     5.0   \n",
      "1  A1U9LTA3EWSNY1  B00006OAQU     5.0   \n",
      "2  A1KJ94X41TJLX0  B00005JYC3     5.0   \n",
      "3  A2ZRNN0L6XI9AM  B000Z3DXT2     5.0   \n",
      "4  A2QQR1OJE3YDH1  B00002R2AC     5.0   \n",
      "\n",
      "                                           preds_als  \n",
      "0  [B00H9A60O4, B000HCZ8EO, B00EZQYC8G, B00NG7JVS...  \n",
      "1  [B000HCZ8EO, B00CTTEKJW, B00EZQYC8G, B00H9A60O...  \n",
      "2  [B00H9A60O4, B00UB76290, B0064PFB9U, B00CTTEKJ...  \n",
      "3  [B00NG7JVSQ, B00NG7JVSQ, B00NG7JVSQ, B00UB7629...  \n",
      "4  [B00F8K9MZQ, B000HCZ8EO, B00H9A60O4, B00CTTEKJ...  \n"
     ]
    }
   ],
   "source": [
    "add_preds_als_to_df(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    train_sparse,\n",
    "    \"preds_als\",\n",
    "    model_als,\n",
    "    model_baseline,\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             user        item  rating  \\\n",
      "0  A18A2Q0UNZU1LQ  B00FFINUJK     5.0   \n",
      "1  A1U9LTA3EWSNY1  B00006OAQU     5.0   \n",
      "2  A1KJ94X41TJLX0  B00005JYC3     5.0   \n",
      "3  A2ZRNN0L6XI9AM  B000Z3DXT2     5.0   \n",
      "4  A2QQR1OJE3YDH1  B00002R2AC     5.0   \n",
      "\n",
      "                                           preds_als  \n",
      "0  [B00H9A60O4, B000HCZ8EO, B00EZQYC8G, B00NG7JVS...  \n",
      "1  [B000HCZ8EO, B00CTTEKJW, B00EZQYC8G, B00H9A60O...  \n",
      "2  [B00H9A60O4, B00UB76290, B0064PFB9U, B00CTTEKJ...  \n",
      "3  [B00NG7JVSQ, B00NG7JVSQ, B00NG7JVSQ, B00UB7629...  \n",
      "4  [B00F8K9MZQ, B000HCZ8EO, B00H9A60O4, B00CTTEKJ...  \n"
     ]
    }
   ],
   "source": [
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@10 =    0.094\n",
      "MRR@10 =   0.037\n",
      "NDCG@10 =  0.050\n",
      "recall =   0.096\n"
     ]
    }
   ],
   "source": [
    "print_metrics(df_test, 'preds_als')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы фильтрация работала, разреженность должна быть меньше чем приблизительно 99.5%. У нас слишком большая разреженность матрицы, поэтому данный метод в нашем случае не подходит (как показано выше: Sparsity 99.8 %). Также, исходная матрица слишком велика для вычислений в ОЗУ, поэтому пришлось значительно ограничить кол-во пользователей и товаров для оценок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "| Model |HR@10|Recall|MRR@10|NDCG@10|\n",
    "|---|---|---|---|---|\n",
    "| Простая статистика top n (Baseline Model) |0.091|0.092|0.038|0.051|\n",
    "| Apriori + Baseline Model | 0.110 | 0.111 | 0.065 | 0.076 |\n",
    "| Slope One + Baseline Model | 0.092 | 0.094 | 0.036 | 0.049 |\n",
    "| ALS + Baseline Model * | 0.094 | 0.096 | 0.037 | 0.050 |\n",
    "\n",
    "[*] Модель ALS в нашем случае не подошла по техническим ограничениям (sparsity — слишком большая разреженность матрицы).<br />\n",
    "\n",
    "Добавление анализа Apriori улучшило результаты по метрикам.<br />\n",
    "Модель Slope One на данной задаче не дала заметного улучшения результата.<br />\n",
    "\n",
    "Лучшие метрики у модели с применением алгоритма Apriori. При необходимости, дальнейшие улучшения можно пробовать получить (ценой усложнения и ухудшения поддерживаемости в production) с помощью Stacking с применением модели LightFM или градиентного бустинга catboost в качестве мета-модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
