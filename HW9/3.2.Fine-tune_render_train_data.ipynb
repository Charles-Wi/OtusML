{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SDwGsUsAmHd"
   },
   "source": [
    "# Fine-tune\n",
    "\n",
    "Чтобы улучшить точность predictions основной модели: обучим на тренировочном наборе данных корректирующию полносвязную нейронную сеть (FNN) совместно в основной моделью (Chronos Bolt base).\n",
    "\n",
    "Корректирующая FNN будет получать на вход выход основной модели и выдавать корректирующие числа в пределах (-1; 1), которые будут умножаться на выбранный коэффициент (для массштабирования коррекций) и прибавляться к единице. В результате будут вычисляться коэффициенты для умножения точек выхода основной модели.\n",
    "\n",
    "## Сгенерируем тренировочный набор данных для FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a2Pv9VRsAmHe"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from etna.datasets import TSDataset\n",
    "from etna.metrics import R2, SMAPE\n",
    "from etna.models.nn import ChronosBoltModel\n",
    "from etna.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Rd3arBlAmHg"
   },
   "source": [
    "## Определения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0r7Z8-7RAmHg"
   },
   "outputs": [],
   "source": [
    "def load_df(path: str):\n",
    "    \"\"\"Load data and return as dataframe\"\"\"\n",
    "    df = pd.read_csv(path, usecols=['date_time', 'traffic_volume'])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['index'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def df_to_etna_ts(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"Convert df to ETNA format\"\"\"\n",
    "    df[\"segment\"] = \"metro\"\n",
    "    df_processed = df.rename(\n",
    "        columns={\"date_time\": \"timestamp\", \"traffic_volume\": \"target\"}\n",
    "    )\n",
    "    return TSDataset(df=TSDataset.to_dataset(df_processed), freq=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 84  # Объём тренировки FNN\n",
    "START_POS = 23590\n",
    "PERIOD = 24 * 7\n",
    "HORIZON = PERIOD * 2\n",
    "TRAIN_SIZE = 24 * 90  # Объём тренировки трансформерной модели (в prompt)\n",
    "\n",
    "metrics = [SMAPE(), R2()]\n",
    "\n",
    "set_seed(1)\n",
    "\n",
    "path_to_chronos_bolt_model = \"H:\\\\Инструменты\\\\Windows\\\\GPT or another LLM\\\n",
    "\\\\amazon chronos-bolt-base 2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btOIrN5GAmHh"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAvZvh1VAmHh",
    "outputId": "02eeb419-c18c-4f7a-823b-807f166a2b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date_time  traffic_volume\n",
      "0      2016-01-01 01:00:00            1550\n",
      "1      2016-01-01 02:00:00            1134\n",
      "2      2016-01-01 03:00:00             719\n",
      "3      2016-01-01 04:00:00             533\n",
      "4      2016-01-01 05:00:00             586\n",
      "...                    ...             ...\n",
      "23753  2018-09-16 18:00:00            3701\n",
      "23754  2018-09-16 19:00:00            3400\n",
      "23755  2018-09-16 20:00:00            3092\n",
      "23756  2018-09-16 21:00:00            2623\n",
      "23757  2018-09-16 22:00:00            1725\n",
      "\n",
      "[23758 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = load_df(\"Metro_Interstate_Traffic_Volume_train.csv\")\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получаем тренировочный набор данных для FNN\n",
    "\n",
    "В контекст Chronos Bolt будут помещаться данные за квартал.<br />\n",
    "Будем генерировать данные по две недели начиная с воскресения 23:00 (как в тестовом наборе данных).<br />\n",
    "Смещать данные будем всё дальше в прошлое по целому числу недель, чтобы начало inference всегда было как в тестовом наборе данных: 23:00 воскресения.\n",
    "\n",
    "Правая граница диапазона выбрана так, чтобы не пересекаться с тестовым набором данных (чтобы исключить утечку тестовых данных в тренировку)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chronos_bolt = ChronosBoltModel(\n",
    "    path_or_url=path_to_chronos_bolt_model,\n",
    "    encoder_length=TRAIN_SIZE\n",
    ")\n",
    "\n",
    "pipeline_etna_bolt = Pipeline(\n",
    "    model=model_chronos_bolt,\n",
    "    horizon=HORIZON,\n",
    "    transforms=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_iter(df: pd.core.frame.DataFrame,\n",
    "               start_pos: int,\n",
    "               n: int,\n",
    "               size_train: int,\n",
    "               size_infer: int,\n",
    "               period: int,\n",
    "               pipeline_etna: Pipeline):\n",
    "    \"\"\"Execute infer by size_infer period.\"\"\"\n",
    "    i = start_pos - n * period - size_train - 1\n",
    "    ts = df_to_etna_ts(df.loc[i:i+size_train-size_infer])\n",
    "    ts_predict = pipeline_etna.forecast(ts)\n",
    "    df_predict = ts_predict.df\n",
    "    y_predict_as_list = list(df_predict[\"metro\"][\"target\"])\n",
    "    y_true = df.loc[i+size_train-size_infer+1:i+size_train]\n",
    "    y_true_as_list = list(y_true[\"traffic_volume\"])\n",
    "    return y_predict_as_list, y_true_as_list, df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_infer(df: pd.core.frame.DataFrame,\n",
    "             start_pos: int,\n",
    "             size_train: int,\n",
    "             size_infer: int,\n",
    "             period: int,\n",
    "             pipeline_etna: Pipeline,\n",
    "             name_of_output_file: str):\n",
    "    \"\"\"Run inference and save to a file\"\"\"\n",
    "    with open(name_of_output_file, \"wt\") as file_train:\n",
    "        file_train.write(\"predict;test\\n\")\n",
    "\n",
    "        for i in tqdm(range(N_TRAIN)):\n",
    "            y_predict, y_true, _ = infer_iter(\n",
    "                df,\n",
    "                start_pos,\n",
    "                i,\n",
    "                size_train,\n",
    "                size_infer,\n",
    "                period,\n",
    "                pipeline_etna\n",
    "            )\n",
    "            file_train.write(str(y_predict)+\";\"+str(y_true)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что правая граница тренировки не пересекается с тестовым набором данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment                    metro\n",
      "feature                   target\n",
      "timestamp                       \n",
      "2018-08-26 23:00:00  1239.717773\n",
      "2018-08-27 00:00:00   697.261475\n",
      "2018-08-27 01:00:00   439.586182\n",
      "2018-08-27 02:00:00   357.514160\n",
      "2018-08-27 03:00:00   383.107422\n",
      "...                          ...\n",
      "2018-09-09 18:00:00  3816.564209\n",
      "2018-09-09 19:00:00  3352.195068\n",
      "2018-09-09 20:00:00  2953.060791\n",
      "2018-09-09 21:00:00  2687.598877\n",
      "2018-09-09 22:00:00  2126.250977\n",
      "\n",
      "[336 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "_, _, control_data = infer_iter(\n",
    "    df_train,\n",
    "    START_POS,\n",
    "    0,\n",
    "    TRAIN_SIZE,\n",
    "    HORIZON,\n",
    "    PERIOD,\n",
    "    pipeline_etna_bolt\n",
    ")\n",
    "print(control_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что крайнее правое значение prediction заканчивается 2018-09-09, а тестовый набор данных начинается с 2018-09-16 — утечка тестовых данных в тренировку отсутствует.\n",
    "\n",
    "Выполним вычисление и сохранение тренировочных данных для FNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:53<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "do_infer(df_train,\n",
    "         START_POS,\n",
    "         TRAIN_SIZE,\n",
    "         HORIZON,\n",
    "         PERIOD,\n",
    "         pipeline_etna_bolt,\n",
    "         \"fnn_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы сохранили тренировочный dataset для FNN в файл `fnn_train.csv`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
